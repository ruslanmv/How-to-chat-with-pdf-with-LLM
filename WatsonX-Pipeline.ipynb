{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1c5caa",
   "metadata": {},
   "source": [
    "# Environment test for WatsonX.ai  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473b1895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to create bearer\n",
      "Bearer retrieved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import TensorflowHubEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import pandas as pd\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.MAX_NEW_TOKENS: 200,\n",
    "    GenParams.MIN_NEW_TOKENS: 0,\n",
    "    GenParams.STOP_SEQUENCES: [\"\\n\"],\n",
    "    GenParams.REPETITION_PENALTY:1\n",
    "    }\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "project_id = os.getenv(\"PROJECT_ID\", None)\n",
    "credentials = {\n",
    "        \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "        \"apikey\": os.getenv(\"API_KEY\", None)\n",
    "        }    \n",
    "#this cell should never fail, and will produce no output\n",
    "import requests\n",
    "\n",
    "def getBearer(apikey):\n",
    "    form = {'apikey': apikey, 'grant_type': \"urn:ibm:params:oauth:grant-type:apikey\"}\n",
    "    print(\"About to create bearer\")\n",
    "#    print(form)\n",
    "    response = requests.post(\"https://iam.cloud.ibm.com/oidc/token\", data = form)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Bad response code retrieving token\")\n",
    "        raise Exception(\"Failed to get token, invalid status\")\n",
    "    json = response.json()\n",
    "    if not json:\n",
    "        print(\"Invalid/no JSON retrieving token\")\n",
    "        raise Exception(\"Failed to get token, invalid response\")\n",
    "    print(\"Bearer retrieved\")\n",
    "    return json.get(\"access_token\")\n",
    "\n",
    "credentials[\"token\"] = getBearer(credentials[\"apikey\"])\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "model_id = ModelTypes.LLAMA_2_70B_CHAT\n",
    "\n",
    "# Initialize the Watsonx foundation model\n",
    "llama_model = Model(\n",
    "    model_id=model_id, \n",
    "    params=parameters, \n",
    "    credentials=credentials,\n",
    "    project_id=project_id)\n",
    "\n",
    "\n",
    "# Function to get text from PDF documents\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        text += \" \".join(page.extract_text() for page in pdf_reader.pages)\n",
    "    return text\n",
    "\n",
    "# Function to split text into chunks\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "# Function to create a vector store\n",
    "def get_vectorstore(text_chunks):\n",
    "    url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\"\n",
    "    #embeddings = OpenAIEmbeddings()\n",
    "    #embeddings = HuggingFaceInstructEmbeddings() \n",
    "    embeddings  = TensorflowHubEmbeddings(model_url=url)   \n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "# Function to create a conversation chain\n",
    "def get_conversation_chain(vectorstore):\n",
    "    #llm = ChatOpenAI()\n",
    "    #llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "    llm=llama_model.to_langchain()\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    return conversation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf9cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model_flan(question):\n",
    "    \n",
    "    parameters = {\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.MAX_NEW_TOKENS: 50,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    #GenParams.STOP_SEQUENCES: [\"\\n\"],\n",
    "    \n",
    "    GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"],\n",
    "    GenParams.REPETITION_PENALTY:1,\n",
    "    \n",
    "    }    \n",
    "    \n",
    "    # Initialize the Watsonx foundation model\n",
    "    llm_model= Model(\n",
    "        model_id=ModelTypes['FLAN_T5_XXL'], \n",
    "        params=parameters, \n",
    "        credentials=credentials,\n",
    "        project_id=project_id)\n",
    "    prompt = f\"Considering the following question, generate 3 keywords are most significant to use when searching in the Arxiv API ,provide your response as a Python list: {question}. \"\n",
    "    result=llm_model.generate(prompt)['results'][0]['generated_text']\n",
    "\n",
    "    # Convert string to a list of individual words\n",
    "    word_list = result.split(', ')    \n",
    "    \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c23335",
   "metadata": {},
   "outputs": [],
   "source": [
    "question= \"What are the current therapies with Tinnitus?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034b908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_list=call_model_flan(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e37c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = list(set(original_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a64695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tinnitus', 'therapy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400e5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full topic creation\n",
    "topic = ' '.join(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40104cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topic to search is: 'tinnitus therapy' \n"
     ]
    }
   ],
   "source": [
    "print(\"The topic to search is: '{}' \".format(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4793fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_search(topic):\n",
    "    print(\"Searching on Arxiv: '{}' \".format(topic))\n",
    "    # combinations of single topics\n",
    "    titles = list()\n",
    "    authors = list()\n",
    "    summary = list()\n",
    "    pdf_url = list()\n",
    "    import arxiv\n",
    "    search = arxiv.Search(\n",
    "      query = topic,\n",
    "      max_results = 10,\n",
    "      sort_by = arxiv.SortCriterion.Relevance\n",
    "       #SubmittedDate #TODO Include it\n",
    "    )\n",
    "    print('Fetching items for token: {}'.format(topic))  \n",
    "    titles = [result.title for result in arxiv.Client().results(search)]\n",
    "    authors = [result.authors for result in arxiv.Client().results(search)]\n",
    "    summary = [result.summary for result in arxiv.Client().results(search)]\n",
    "    entry_id = [result.entry_id for result in arxiv.Client().results(search)]\n",
    "    pdf_url = [result.pdf_url for result in arxiv.Client().results(search)]\n",
    "    categories = [result.categories for result in arxiv.Client().results(search)]\n",
    "    comment = [result.comment for result in arxiv.Client().results(search)]\n",
    "    doi = [result.doi for result in arxiv.Client().results(search)]\n",
    "    published = [result.published for result in arxiv.Client().results(search)]\n",
    "    df = pd.DataFrame({\n",
    "        'title': titles,\n",
    "        'authors': authors,\n",
    "        'summary': summary,\n",
    "        'pdf_url': pdf_url,\n",
    "        'categories': categories,\n",
    "        'published': published\n",
    "    })\n",
    "    url_list =df['pdf_url'].values.tolist()\n",
    "\n",
    "    import requests\n",
    "    import os\n",
    "    import tempfile\n",
    "\n",
    "    def download_pdf(url, filename):\n",
    "        response = requests.get(url)\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "    def download_pdf_files(url_list):\n",
    "        temp_dir = tempfile.gettempdir()  # Get the temporary directory path\n",
    "        downloaded_files = []  # List to store downloaded file paths\n",
    "        for i, url in enumerate(url_list):\n",
    "            filename = os.path.join(temp_dir, f'file_{i+1}.pdf')  # Set the absolute path in the temporary directory\n",
    "            download_pdf(url, filename)\n",
    "            downloaded_files.append(filename)  # Append the file name to the list with the path\n",
    "            print(f'Downloaded: {filename}')\n",
    "\n",
    "        return downloaded_files  # Return the list of downloaded file names\n",
    "\n",
    "    def delete_files_in_temp():\n",
    "        temp_dir = tempfile.gettempdir()  # Get the temporary directory path\n",
    "        for file in os.listdir(temp_dir):\n",
    "            file_path = os.path.join(temp_dir, file)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                    print(f\"Deleted: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file_path}: {e}\")\n",
    "\n",
    "\n",
    "    downloaded_files = download_pdf_files(url_list)\n",
    "    return downloaded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66cbfe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching on Arxiv: 'tinnitus therapy' \n",
      "Fetching items for token: tinnitus therapy\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_1.pdf\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_2.pdf\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_3.pdf\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_4.pdf\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_5.pdf\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_6.pdf\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_7.pdf\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_8.pdf\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_9.pdf\n",
      "Downloaded: C:\\Users\\rusla\\AppData\\Local\\Temp\\file_10.pdf\n"
     ]
    }
   ],
   "source": [
    "downloaded_files =arxiv_search(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c03a7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_1.pdf',\n",
       " 'C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_2.pdf',\n",
       " 'C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_3.pdf',\n",
       " 'C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_4.pdf',\n",
       " 'C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_5.pdf',\n",
       " 'C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_6.pdf',\n",
       " 'C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_7.pdf',\n",
       " 'C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_8.pdf',\n",
       " 'C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_9.pdf',\n",
       " 'C:\\\\Users\\\\rusla\\\\AppData\\\\Local\\\\Temp\\\\file_10.pdf']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloaded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c6f133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current working directory\n",
    "#current_working_directory = os.getcwd()# Path\n",
    "# Join various path components \n",
    "#pdf_path=[os.path.join(current_working_directory, \"documents\", \"example.pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16c3701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the downloaded files to path\n",
    "pdf_path= downloaded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71758fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PDF text and split into chunks\n",
    "raw_text = get_pdf_text(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83c6e982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1144, which is longer than the specified 1000\n",
      "Created a chunk of size 1212, which is longer than the specified 1000\n",
      "Created a chunk of size 1211, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_chunks = get_text_chunks(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af1e1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store and conversation chain\n",
    "vectorstore = get_vectorstore(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb68a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=llama_model.to_langchain()\n",
    "memory = ConversationBufferMemory(memory_key='chat_history',\n",
    "                                    return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e192c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efd84a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96c52f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the current therapies with Tinnitus?\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4296bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt={\"question\": query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fb4b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conversation_chain(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5740b0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the current therapies with Tinnitus?',\n",
       " 'chat_history': [HumanMessage(content='What are the current therapies with Tinnitus?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='  Unfortunately, there are currently no universally effective clinical methods for the diagnosis and treatment of tinnitus. Researchers have proposed that assessing abnormal neural activity through EEG signals may aid in the diagnosis of tinnitus. In the early stages, evaluation of EEG signals and further diagnosis were usually done by clinical specialists. Some researchers have attempted to use neurofeedback to assist in tinnitus therapy, and all patients claimed tinnitus relief with decreased EEG activity observed.', additional_kwargs={}, example=False)],\n",
       " 'answer': '  Unfortunately, there are currently no universally effective clinical methods for the diagnosis and treatment of tinnitus. Researchers have proposed that assessing abnormal neural activity through EEG signals may aid in the diagnosis of tinnitus. In the early stages, evaluation of EEG signals and further diagnosis were usually done by clinical specialists. Some researchers have attempted to use neurofeedback to assist in tinnitus therapy, and all patients claimed tinnitus relief with decreased EEG activity observed.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48649ec",
   "metadata": {},
   "source": [
    "\n",
    "To include instructions to the large language model in the python code above, you can use the **parameters** argument when calling the conversation_chain.generate() method. This argument is a dictionary that can contain any additional parameters that you want to pass to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c990f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"instruction\": \"Answer the following question using only information from the article. If there is no good answer in the article, say I don't know\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d619bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6c450e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt={\"question\": query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "deafbe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conversation_chain(prompt, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6241ad0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '  The current therapies for tinnitus include neurofeedback, which was first attempted by Gosepath et al. [26] to assist tinnitus therapy. With the decreased activity of EEG observed, all patients claimed tinnitus relief. The researchers emphasize that the assessment of abnormal neural activity as assessed by EEG signals may aid in the diagnosis of tinnitus. However, there is currently no universally effective clinical method for subjective tinnitus diagnosis and treatment [25].'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7a238d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the temperature in Genova\"\n",
    "prompt={\"question\": query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e474b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conversation_chain(prompt,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a79fb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \"  I don't know.\\n\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4be38577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='What is the topic about', additional_kwargs={}, example=False), AIMessage(content=' The topic is about a research study on tinnitus analysis using EEG signals, specifically proposing a new method called Side-aware Meta-Siamese-AutoEncoder (SMeta-SAE) for tinnitus diagnosis and side information prediction.', additional_kwargs={}, example=False), HumanMessage(content='What are the current therapies with Tinnitus?', additional_kwargs={}, example=False), AIMessage(content='  According to the provided text, current therapies for tinnitus include neurofeedback, tinnitus retraining therapy, and cognitive behavioral therapy. Additionally, researchers have proposed using the assessment of abnormal neural activity as assessed by EEG signals to aid in the diagnosis of tinnitus.', additional_kwargs={}, example=False), HumanMessage(content='What are the current therapies with Tinnitus?', additional_kwargs={}, example=False), AIMessage(content='  According to the provided text, current therapies for tinnitus include neurofeedback, tinnitus retraining therapy, and cognitive behavioral therapy. Additionally, researchers have proposed using the assessment of abnormal neural activity as assessed by EEG signals to aid in the diagnosis of tinnitus.', additional_kwargs={}, example=False), HumanMessage(content='What is the temperature in Genova', additional_kwargs={}, example=False), AIMessage(content=\"  I don't know.\\n\", additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, human_prefix='Human', ai_prefix='AI', memory_key='chat_history')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93c4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatpdf)",
   "language": "python",
   "name": "chatpdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
